{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d3750df3",
      "metadata": {
        "id": "d3750df3"
      },
      "source": [
        "# Exercise: Object Counting Using YOLO with a Line in the Middle of the Frame\n",
        "In this exercise, you will implement an object counting system using YOLOv8. You will process a video and count the number of objects crossing a line drawn in the middle of the frame. Follow the steps below to complete the exercise.\n",
        "\n",
        "## Objective:\n",
        "The goal is to load a video, detect objects, count them as they cross a line, and save the processed video with the results.\n",
        "\n",
        "## Steps to Complete:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0c358a6",
      "metadata": {
        "id": "c0c358a6"
      },
      "source": [
        "### Step 1: Install the Required Libraries\n",
        "- Install the `ultralytics` library using pip to work with YOLOv8.\n",
        "- Also ensure you have OpenCV installed for video processing.\n",
        "\n",
        "_Hint_: You can install a library using the `!pip install` command in a code cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b485770c",
      "metadata": {
        "id": "b485770c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5972ffe2-9c67-402c-8c90-8d36b13ccfa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m871.1/871.1 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics -q"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3418c064",
      "metadata": {
        "id": "3418c064"
      },
      "source": [
        "### Step 2: Import the Libraries\n",
        "- Import the necessary libraries, including `cv2` from OpenCV and `YOLO` from `ultralytics`.\n",
        "- You will also need to import any other required libraries for object counting and video handling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b0204dd1",
      "metadata": {
        "id": "b0204dd1"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO, solutions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d18b3ee",
      "metadata": {
        "id": "0d18b3ee"
      },
      "source": [
        "### Step 3: Load the YOLO Model\n",
        "- Load the pre-trained YOLOv8 model (e.g., `yolov8n.pt`) to perform object detection and tracking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d6d8b7ca",
      "metadata": {
        "id": "d6d8b7ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aa8e995-e8e5-4a3d-811d-125eb9f1f342"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 115MB/s]\n"
          ]
        }
      ],
      "source": [
        "model=YOLO('yolov8n.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a013f91a",
      "metadata": {
        "id": "a013f91a"
      },
      "source": [
        "### Step 4: Capture and Process the Video\n",
        "- Use OpenCV to capture the video from a specified file path.\n",
        "- Ensure the video file opens successfully and retrieve the video properties (such as width, height, and frames per second)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "4969f806",
      "metadata": {
        "id": "4969f806",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66a854fd-a0e0-4b12-e62e-2027c3082056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "cap = cv2.VideoCapture('vehicle-counting.mp4')\n",
        "print(cap.isOpened())\n",
        "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76c53c44",
      "metadata": {
        "id": "76c53c44"
      },
      "source": [
        "### Step 5: Define the Line in the Middle of the Frame\n",
        "- Calculate the vertical middle of the frame using the height of the video.\n",
        "- Define two points to represent a horizontal line in the middle of the frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "f917b88a",
      "metadata": {
        "id": "f917b88a"
      },
      "outputs": [],
      "source": [
        "mid_y=h//2\n",
        "line_points=[(20,mid_y),(w-20,mid_y)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23e45736",
      "metadata": {
        "id": "23e45736"
      },
      "source": [
        "### Step 6: Set Up the Video Writer\n",
        "- Create a video writer object to save the output video in MP4 format.\n",
        "- Choose the appropriate codec and ensure the output video properties match the input video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "79307270",
      "metadata": {
        "id": "79307270"
      },
      "outputs": [],
      "source": [
        "video_writer = cv2.VideoWriter('object_counting_output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b7f4ffd",
      "metadata": {
        "id": "6b7f4ffd"
      },
      "source": [
        "### Step 7: Initialize the Object Counter\n",
        "- Use the `solutions.ObjectCounter` class to handle the object counting logic.\n",
        "- Pass in the necessary parameters, including the line points, object names, and any visual settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "79b41d23",
      "metadata": {
        "id": "79b41d23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2805e77-63d6-4dae-a2c7-f99dc5279f3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ Environment does not support cv2.imshow() or PIL Image.show()\n",
            "\n",
            "Line Counter Initiated.\n"
          ]
        }
      ],
      "source": [
        "counter = solutions.ObjectCounter(\n",
        "    view_img=False,\n",
        "    reg_pts=line_points,\n",
        "    names=model.names,\n",
        "    draw_tracks=True,\n",
        "    line_thickness=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edf12972",
      "metadata": {
        "id": "edf12972"
      },
      "source": [
        "### Step 8: Process the Video Frames\n",
        "- Loop through each frame of the video using OpenCV.\n",
        "- Apply YOLOv8 to detect and track objects in each frame.\n",
        "- Use the object counter to count the number of objects crossing the line.\n",
        "- Write each processed frame to the output video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "a0228c1c",
      "metadata": {
        "id": "a0228c1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d72459cf-df3b-4aa1-a821-1400fdd1be4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 cars, 1 truck, 254.0ms\n",
            "Speed: 16.1ms preprocess, 254.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 273.7ms\n",
            "Speed: 8.7ms preprocess, 273.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 289.0ms\n",
            "Speed: 5.1ms preprocess, 289.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 253.0ms\n",
            "Speed: 5.4ms preprocess, 253.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 180.3ms\n",
            "Speed: 4.8ms preprocess, 180.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 196.4ms\n",
            "Speed: 5.2ms preprocess, 196.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 177.7ms\n",
            "Speed: 4.9ms preprocess, 177.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 162.7ms\n",
            "Speed: 5.1ms preprocess, 162.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 197.0ms\n",
            "Speed: 4.9ms preprocess, 197.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 186.3ms\n",
            "Speed: 9.2ms preprocess, 186.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 172.7ms\n",
            "Speed: 7.6ms preprocess, 172.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 172.2ms\n",
            "Speed: 4.9ms preprocess, 172.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 162.9ms\n",
            "Speed: 5.0ms preprocess, 162.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 200.2ms\n",
            "Speed: 11.2ms preprocess, 200.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 177.4ms\n",
            "Speed: 6.3ms preprocess, 177.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 180.4ms\n",
            "Speed: 8.8ms preprocess, 180.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 161.3ms\n",
            "Speed: 4.9ms preprocess, 161.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 187.8ms\n",
            "Speed: 5.7ms preprocess, 187.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 175.1ms\n",
            "Speed: 5.0ms preprocess, 175.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 167.5ms\n",
            "Speed: 4.8ms preprocess, 167.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 173.8ms\n",
            "Speed: 5.7ms preprocess, 173.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 187.7ms\n",
            "Speed: 5.6ms preprocess, 187.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 204.8ms\n",
            "Speed: 7.1ms preprocess, 204.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 172.4ms\n",
            "Speed: 6.0ms preprocess, 172.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 189.2ms\n",
            "Speed: 5.7ms preprocess, 189.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 180.6ms\n",
            "Speed: 5.1ms preprocess, 180.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 2 trucks, 220.3ms\n",
            "Speed: 5.0ms preprocess, 220.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 285.6ms\n",
            "Speed: 5.0ms preprocess, 285.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 272.9ms\n",
            "Speed: 5.2ms preprocess, 272.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 311.8ms\n",
            "Speed: 4.9ms preprocess, 311.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 317.6ms\n",
            "Speed: 4.7ms preprocess, 317.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 161.9ms\n",
            "Speed: 5.1ms preprocess, 161.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 168.8ms\n",
            "Speed: 5.4ms preprocess, 168.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 195.1ms\n",
            "Speed: 5.7ms preprocess, 195.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 164.6ms\n",
            "Speed: 4.9ms preprocess, 164.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 171.5ms\n",
            "Speed: 5.2ms preprocess, 171.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 187.8ms\n",
            "Speed: 5.8ms preprocess, 187.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 179.8ms\n",
            "Speed: 4.9ms preprocess, 179.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 190.6ms\n",
            "Speed: 4.7ms preprocess, 190.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 171.5ms\n",
            "Speed: 4.9ms preprocess, 171.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 166.9ms\n",
            "Speed: 5.4ms preprocess, 166.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 195.8ms\n",
            "Speed: 4.9ms preprocess, 195.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 185.0ms\n",
            "Speed: 4.6ms preprocess, 185.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 164.2ms\n",
            "Speed: 5.1ms preprocess, 164.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 203.7ms\n",
            "Speed: 4.9ms preprocess, 203.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 195.9ms\n",
            "Speed: 5.8ms preprocess, 195.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 165.7ms\n",
            "Speed: 4.7ms preprocess, 165.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 174.3ms\n",
            "Speed: 6.3ms preprocess, 174.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 174.1ms\n",
            "Speed: 5.5ms preprocess, 174.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 187.2ms\n",
            "Speed: 8.9ms preprocess, 187.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 173.5ms\n",
            "Speed: 5.0ms preprocess, 173.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 172.9ms\n",
            "Speed: 4.6ms preprocess, 172.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 177.3ms\n",
            "Speed: 4.8ms preprocess, 177.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 259.5ms\n",
            "Speed: 4.7ms preprocess, 259.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 311.4ms\n",
            "Speed: 4.6ms preprocess, 311.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 235.9ms\n",
            "Speed: 11.6ms preprocess, 235.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 294.1ms\n",
            "Speed: 5.2ms preprocess, 294.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 300.7ms\n",
            "Speed: 5.1ms preprocess, 300.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 264.9ms\n",
            "Speed: 4.8ms preprocess, 264.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 196.3ms\n",
            "Speed: 4.8ms preprocess, 196.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 166.6ms\n",
            "Speed: 5.1ms preprocess, 166.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 185.1ms\n",
            "Speed: 4.9ms preprocess, 185.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 165.2ms\n",
            "Speed: 5.6ms preprocess, 165.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 172.4ms\n",
            "Speed: 6.7ms preprocess, 172.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 167.7ms\n",
            "Speed: 5.1ms preprocess, 167.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 188.7ms\n",
            "Speed: 4.7ms preprocess, 188.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 210.3ms\n",
            "Speed: 4.6ms preprocess, 210.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 177.3ms\n",
            "Speed: 4.5ms preprocess, 177.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 161.6ms\n",
            "Speed: 4.8ms preprocess, 161.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 177.2ms\n",
            "Speed: 7.1ms preprocess, 177.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 165.8ms\n",
            "Speed: 4.8ms preprocess, 165.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 174.9ms\n",
            "Speed: 4.8ms preprocess, 174.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 169.0ms\n",
            "Speed: 4.7ms preprocess, 169.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 217.9ms\n",
            "Speed: 4.7ms preprocess, 217.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 173.7ms\n",
            "Speed: 7.5ms preprocess, 173.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 223.2ms\n",
            "Speed: 7.0ms preprocess, 223.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 163.1ms\n",
            "Speed: 6.9ms preprocess, 163.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 204.2ms\n",
            "Speed: 7.7ms preprocess, 204.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 179.4ms\n",
            "Speed: 5.2ms preprocess, 179.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 boat, 165.9ms\n",
            "Speed: 4.6ms preprocess, 165.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 185.3ms\n",
            "Speed: 4.6ms preprocess, 185.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 305.5ms\n",
            "Speed: 10.1ms preprocess, 305.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 259.7ms\n",
            "Speed: 4.8ms preprocess, 259.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 273.4ms\n",
            "Speed: 7.8ms preprocess, 273.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 269.3ms\n",
            "Speed: 25.5ms preprocess, 269.3ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 293.6ms\n",
            "Speed: 15.0ms preprocess, 293.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 231.1ms\n",
            "Speed: 4.8ms preprocess, 231.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 188.7ms\n",
            "Speed: 5.5ms preprocess, 188.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 190.7ms\n",
            "Speed: 4.7ms preprocess, 190.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 185.3ms\n",
            "Speed: 5.1ms preprocess, 185.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 178.9ms\n",
            "Speed: 6.7ms preprocess, 178.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 162.6ms\n",
            "Speed: 7.8ms preprocess, 162.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 180.9ms\n",
            "Speed: 5.4ms preprocess, 180.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 194.0ms\n",
            "Speed: 5.1ms preprocess, 194.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 196.7ms\n",
            "Speed: 4.7ms preprocess, 196.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 172.7ms\n",
            "Speed: 4.9ms preprocess, 172.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 174.8ms\n",
            "Speed: 4.7ms preprocess, 174.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 186.1ms\n",
            "Speed: 6.3ms preprocess, 186.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 180.3ms\n",
            "Speed: 6.3ms preprocess, 180.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 165.7ms\n",
            "Speed: 5.8ms preprocess, 165.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 165.6ms\n",
            "Speed: 4.9ms preprocess, 165.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 213.7ms\n",
            "Speed: 5.1ms preprocess, 213.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 185.2ms\n",
            "Speed: 5.3ms preprocess, 185.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 176.5ms\n",
            "Speed: 7.8ms preprocess, 176.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 180.2ms\n",
            "Speed: 4.7ms preprocess, 180.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 176.1ms\n",
            "Speed: 6.7ms preprocess, 176.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 184.4ms\n",
            "Speed: 5.4ms preprocess, 184.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 168.8ms\n",
            "Speed: 5.1ms preprocess, 168.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 177.1ms\n",
            "Speed: 5.0ms preprocess, 177.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 297.8ms\n",
            "Speed: 4.8ms preprocess, 297.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 261.8ms\n",
            "Speed: 6.1ms preprocess, 261.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 270.9ms\n",
            "Speed: 7.7ms preprocess, 270.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 260.9ms\n",
            "Speed: 4.8ms preprocess, 260.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 332.2ms\n",
            "Speed: 7.0ms preprocess, 332.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 208.6ms\n",
            "Speed: 5.9ms preprocess, 208.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 201.2ms\n",
            "Speed: 5.1ms preprocess, 201.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 truck, 169.1ms\n",
            "Speed: 5.1ms preprocess, 169.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 173.8ms\n",
            "Speed: 5.2ms preprocess, 173.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 167.8ms\n",
            "Speed: 4.9ms preprocess, 167.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 175.4ms\n",
            "Speed: 4.8ms preprocess, 175.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 187.8ms\n",
            "Speed: 5.6ms preprocess, 187.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 163.8ms\n",
            "Speed: 5.9ms preprocess, 163.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 168.0ms\n",
            "Speed: 6.8ms preprocess, 168.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 166.4ms\n",
            "Speed: 5.2ms preprocess, 166.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 177.9ms\n",
            "Speed: 7.1ms preprocess, 177.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 166.1ms\n",
            "Speed: 4.9ms preprocess, 166.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 149.0ms\n",
            "Speed: 5.5ms preprocess, 149.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 160.6ms\n",
            "Speed: 6.8ms preprocess, 160.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 156.7ms\n",
            "Speed: 5.3ms preprocess, 156.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Video frame is empty or video processing has been successfully completed.\n"
          ]
        }
      ],
      "source": [
        "while cap.isOpened():\n",
        "    success, im0 = cap.read()\n",
        "    if not success:\n",
        "        print('Video frame is empty or video processing has been successfully completed.')\n",
        "        break\n",
        "\n",
        "    # Perform object tracking\n",
        "    tracks = model.track(im0, persist=True, show=False)\n",
        "\n",
        "    # Count objects and draw the middle line\n",
        "    im0 = counter.start_counting(im0, tracks)\n",
        "    video_writer.write(im0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52822ce8",
      "metadata": {
        "id": "52822ce8"
      },
      "source": [
        "### Step 9: Release Resources\n",
        "- Once the video processing is complete, release the video capture and writer objects.\n",
        "- Close any OpenCV windows that were opened during the process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "7567e053",
      "metadata": {
        "id": "7567e053"
      },
      "outputs": [],
      "source": [
        "cap.release()\n",
        "video_writer.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c85b11f5",
      "metadata": {
        "id": "c85b11f5"
      },
      "source": [
        "\n",
        "### Conclusion\n",
        "By completing this exercise, you will have implemented an object counting system using YOLOv8 and OpenCV. The final output will be a video with objects counted as they cross a line in the middle of the frame."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}