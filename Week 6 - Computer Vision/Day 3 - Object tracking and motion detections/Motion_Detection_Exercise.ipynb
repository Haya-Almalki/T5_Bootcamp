{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fe5bacbb",
      "metadata": {
        "id": "fe5bacbb"
      },
      "source": [
        "# Exercise: Implementing Motion Detection Using Background Subtraction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3332331",
      "metadata": {
        "id": "a3332331"
      },
      "source": [
        "### Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e17c3591",
      "metadata": {
        "id": "e17c3591"
      },
      "source": [
        "In this exercise, you will implement motion detection in a video using background subtraction. Follow the steps outlined below and write the corresponding code for each step."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2309fa4f",
      "metadata": {
        "id": "2309fa4f"
      },
      "source": [
        "### Step 1: Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "vwqPv3M2l8nz"
      },
      "id": "vwqPv3M2l8nz",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a9183a82",
      "metadata": {
        "id": "a9183a82"
      },
      "source": [
        "### Step 2: Set Up Video Capture"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43ada6fe",
      "metadata": {
        "id": "43ada6fe"
      },
      "source": [
        "Initialize the video capture object by loading the video file (e.g., `video.mp4`). This object will allow you to read frames from the video."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cap=cv2.VideoCapture('Motion_Detection_Test.mp4') # To open video file\n",
        "cap.isOpened()"
      ],
      "metadata": {
        "id": "5YTx_g-fl-QY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5199b8d1-2fd2-4308-c2af-08ae20212ad8"
      },
      "id": "5YTx_g-fl-QY",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0072f6cf",
      "metadata": {
        "id": "0072f6cf"
      },
      "source": [
        "### Step 3: Define the Video Writer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f32d9d6",
      "metadata": {
        "id": "8f32d9d6"
      },
      "source": [
        "Set up a `VideoWriter` object to save the processed video with motion detection. Choose the appropriate codec (e.g., `'mp4v'`) and specify the frame rate and resolution for the output video."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter('motion_output.mp4', fourcc, 20.0, (600, 500)) # frame rate:20 , (width, height)= (600,500)"
      ],
      "metadata": {
        "id": "exSdbEE5l_ut"
      },
      "id": "exSdbEE5l_ut",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f5d81bbd",
      "metadata": {
        "id": "f5d81bbd"
      },
      "source": [
        "### Step 4: Create the Background Subtractor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddd55e96",
      "metadata": {
        "id": "ddd55e96"
      },
      "source": [
        "Use OpenCV's MOG2 background subtractor to create a background model that will help detect moving objects. Set `detectShadows=True` to improve detection accuracy by accounting for shadows."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a background subtractor using MOG2 (calculate disribution)\n",
        "fgbg = cv2.createBackgroundSubtractorMOG2(detectShadows=True)"
      ],
      "metadata": {
        "id": "nr_7PlafmA1H"
      },
      "id": "nr_7PlafmA1H",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "11c3ee89",
      "metadata": {
        "id": "11c3ee89"
      },
      "source": [
        "### Step 5: Process the Video Frame by Frame"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e2c952d",
      "metadata": {
        "id": "6e2c952d"
      },
      "source": [
        "1. In a loop, capture each frame from the video.\n",
        "2. Resize the frame for consistency.\n",
        "3. Apply the background subtractor to detect moving objects in the frame.\n",
        "4. Create a binary thresholded image to isolate the moving objects.\n",
        "5. Apply morphological operations like erosion and dilation to reduce noise and strengthen the detected areas.\n",
        "6. Detect contours (boundaries) of the moving objects.\n",
        "7. For each contour, calculate its area and filter out small movements by considering only contours with areas greater than a certain threshold (e.g., 1200).\n",
        "8. Draw rectangles around the detected moving objects and annotate the motion."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    # Capture each frame of the video\n",
        "    success, img = cap.read()\n",
        "    # Check if the frame is captured successfully\n",
        "    if success:\n",
        "        # Resize the frame for consistency\n",
        "        img = cv2.resize(img, (600, 500))\n",
        "\n",
        "        # Apply the background subtractor to detect moving objects\n",
        "        fgmask = fgbg.apply(img)\n",
        "\n",
        "        # Create a binary thresholded image for better motion detection\n",
        "        _, thresh = cv2.threshold(fgmask.copy(), 180, 255, cv2.THRESH_BINARY) #0 or 255\n",
        "\n",
        "        # Define a kernel for morphological operations\n",
        "        kernel = np.ones((7, 7), np.uint8)\n",
        "\n",
        "        # Apply erosion to remove noise from the thresholded image\n",
        "        thresh = cv2.erode(thresh, kernel)\n",
        "\n",
        "        # Apply dilation to strengthen the detected moving objects\n",
        "        thresh = cv2.dilate(thresh, None, iterations=6)\n",
        "\n",
        "        # Find contours of the detected motion\n",
        "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        # Draw rectangles around detected motion\n",
        "        for contour in contours:\n",
        "            # Calculate the area of the contour\n",
        "            area = cv2.contourArea(contour) # if area small rhis mean there is no motion\n",
        "\n",
        "            # Only consider significant motion (area > 1200)\n",
        "            if area > 1200:\n",
        "                # Get the bounding box coordinates for the motion\n",
        "                x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "                # Draw a rectangle around the detected motion and label it\n",
        "                cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 255), 3)\n",
        "                cv2.putText(img, 'MOTION DETECTED', (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "        # Write the processed frame with motion detection to the output video\n",
        "            out.write(img)\n",
        "\n",
        "    else:\n",
        "        # Break the loop if no more frames are available\n",
        "        break\n"
      ],
      "metadata": {
        "id": "Iyae2b1lmBlS"
      },
      "id": "Iyae2b1lmBlS",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "260f89b2",
      "metadata": {
        "id": "260f89b2"
      },
      "source": [
        "### Step 6: Release Resources"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64a70401",
      "metadata": {
        "id": "64a70401"
      },
      "source": [
        "After processing all the frames, release the video capture and writer objects to free up system resources. Close any OpenCV windows that were opened during the process."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Release the video capture and writer objects\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "# Close all OpenCV windows\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "cnuY8pmNmM_6"
      },
      "id": "cnuY8pmNmM_6",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "66aae989",
      "metadata": {
        "id": "66aae989"
      },
      "source": [
        "### Bonus Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "579a8ce5",
      "metadata": {
        "id": "579a8ce5"
      },
      "source": [
        "Try experimenting with different threshold values, kernel sizes, or codecs to optimize the motion detection and improve the output video quality."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I put kernal size= (3,3), threshold=100"
      ],
      "metadata": {
        "id": "RRihVckMTQnC"
      },
      "id": "RRihVckMTQnC"
    },
    {
      "cell_type": "code",
      "source": [
        "# video writer:\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter('motion_output_Bonus.mp4', fourcc, 20.0, (800, 500)) # frame rate:20 , (width, height)= (800,500)"
      ],
      "metadata": {
        "id": "LtPYq4B8RMAd"
      },
      "id": "LtPYq4B8RMAd",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a background subtractor using MOG2 (calculate disribution)\n",
        "fgbg = cv2.createBackgroundSubtractorMOG2(detectShadows=True)"
      ],
      "metadata": {
        "id": "xi58QDpWRVDO"
      },
      "id": "xi58QDpWRVDO",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    # Capture each frame of the video\n",
        "    success, img = cap.read()\n",
        "    # Check if the frame is captured successfully\n",
        "    if success:\n",
        "        # Resize the frame for consistency\n",
        "        img = cv2.resize(img, (800, 500))\n",
        "\n",
        "        # Apply the background subtractor to detect moving objects\n",
        "        fgmask = fgbg.apply(img)\n",
        "\n",
        "        # Create a binary thresholded image for better motion detection\n",
        "        _, thresh = cv2.threshold(fgmask.copy(), 10, 255, cv2.THRESH_BINARY) #0 or 255\n",
        "\n",
        "        # Define a kernel for morphological operations\n",
        "        kernel = np.ones((3, 3), np.uint8)\n",
        "\n",
        "        # Apply erosion to remove noise from the thresholded image\n",
        "        thresh = cv2.erode(thresh, kernel)\n",
        "\n",
        "        # Apply dilation to strengthen the detected moving objects\n",
        "        thresh = cv2.dilate(thresh, None, iterations=6)\n",
        "\n",
        "        # Find contours of the detected motion\n",
        "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        # Draw rectangles around detected motion\n",
        "        for contour in contours:\n",
        "            # Calculate the area of the contour\n",
        "            area = cv2.contourArea(contour) # if area small rhis mean there is no motion\n",
        "\n",
        "            # Only consider significant motion (area > 1200)\n",
        "            if area > 1200:\n",
        "                # Get the bounding box coordinates for the motion\n",
        "                x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "                # Draw a rectangle around the detected motion and label it\n",
        "                cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 255), 3)\n",
        "                cv2.putText(img, 'MOTION DETECTED', (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "        # Write the processed frame with motion detection to the output video\n",
        "            out.write(img)\n",
        "\n",
        "    else:\n",
        "        # Break the loop if no more frames are available\n",
        "        break\n"
      ],
      "metadata": {
        "id": "OZJeMOOYRAbV"
      },
      "id": "OZJeMOOYRAbV",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Release the video capture and writer objects\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "# Close all OpenCV windows\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "5qbYmmuZR_y-"
      },
      "id": "5qbYmmuZR_y-",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U1kRz8u-SHON"
      },
      "id": "U1kRz8u-SHON",
      "execution_count": 27,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}